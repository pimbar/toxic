{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TMO 2017-2018: practica-toxic.py\n",
    "# Dpto. de C. de la Computación e I.A. (Univ. de Sevilla)\n",
    "#=====================================================================\n",
    "\n",
    "# ********************************************************************\n",
    "# Nombre: Antonio\n",
    "# Apellidos: Ramírez Hurtado\n",
    "# ********************************************************************\n",
    "\n",
    "# **************************** IMPORTANTE ****************************\n",
    "# - Recordar escribir el nombre en la cabecera de este fichero.\n",
    "# ********************************************************************\n",
    "\n",
    "# ********************************************************************\n",
    "# HONESTIDAD ACADÉMICA Y COPIAS: la realización de los ejercicios es\n",
    "# un trabajo personal, por lo que deben completarse por cada\n",
    "# estudiante de manera individual.  La discusión y el intercambio de\n",
    "# información de carácter general con los compañeros se permite (e\n",
    "# incluso se recomienda), pero NO AL NIVEL DE CÓDIGO. Igualmente el\n",
    "# remitir código de terceros, obtenido a través de la red o cualquier\n",
    "# otro medio, se considerará plagio.\n",
    "\n",
    "# Cualquier plagio o compartición de código que se detecte significará\n",
    "# automáticamente la calificación de CERO EN LA ASIGNATURA para TODOS\n",
    "# los alumnos involucrados. \n",
    "# ********************************************************************\n",
    "\n",
    "# Se pide crear un modelo de clasificación con alguno de los algoritmos\n",
    "# vistos en clase e implementados en la librería scikit-learn, también se\n",
    "# permite el uso de xgboost y keras (tensorflow). Se valorará\n",
    "# el ajuste de parámetros realizado (aplicando validación cruzada), así como\n",
    "# la transformaciones sobre los datos desarrolladas para mejorar el calidad\n",
    "# (score) del modelo por validación cruzada (un buen ejemplo es el notebook\n",
    "# Left que se puede encontrar en la enseñanza virtual)\n",
    "\n",
    "# El conjunto de datos corresponde a comentarios realizados en wikipedia.\n",
    "# Se pretende determinar si los comentarios tiene un carga negativa o no.\n",
    "# que un anuncio dado tendrá para la comunidad de usuarios de este portal.\n",
    "# Cada comentario puede ser clasificado como tóxico, muy tóxico, obsceno,\n",
    "# insultante, con carga de odio y/o amenazante.\n",
    "\n",
    "#    1. De los texto se pueden obtener atributos como la longitud, número \n",
    "#       de palabras, número de palabras únicas, número de mayúsculas, etc... \n",
    "#       También se pueden aplicar técnicas de vectorización de textos como \n",
    "#       CountVectorizer o TF-IDF entre otras. \n",
    "#    2. Se puede usar diferentes algoritmos: regresión lineal, naive bayes, \n",
    "#       random forest y despues intentar ensamblarlos (obtener la media de las\n",
    "#       predicciones)\n",
    "\n",
    "# Estas son algunas de las tranformaciones que se pueden realizar, pero no las\n",
    "# únicas. Cualquier otra transformación que se lleve a cabo sobre los datos\n",
    "# será tenida en cuenta positivamente.\n",
    "\n",
    "# Se deberá entregar este archivo con las implementaciones realizadas y\n",
    "# comentadas, el archivo de predicciones del mejor modelo encontrado y el score \n",
    "# asociado por cross-validación y el proporcionado por kaggle (enviar a \n",
    "# dsolis@us.es)\n",
    "\n",
    "# Toda la información necesaria y los conjuntos de datos se pueden encontrar en:\n",
    "# https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge\n",
    "\n",
    "# *******************************************************************\n",
    "# IMPORTANTE: El plazo de entrega es hasta la finalización de la \n",
    "# competición (20 de Febrero).\n",
    "# ********************************************************************\n",
    "\n",
    "# *******************************************************************\n",
    "# IMPORTANTE: La competición está activa. Debéis subir las predicciones\n",
    "# y que la plataforma os dé el score sobre el test. Podeis usar el nombre\n",
    "# de usuario que considereis oportuno.\n",
    "# ********************************************************************\n",
    "\n",
    "# ********************************************************************\n",
    "# IMPORTANTE: Se pueden consultar y usar los ejemplos de código y \n",
    "# transformaciones encontradas en: \n",
    "# https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/kernels\n",
    "# ********************************************************************\n",
    "\n",
    "# ********************************************************************\n",
    "# IMPORTANTE: Para resolver cualquier duda contactar con David Solís \n",
    "# (dsolis@us.es)\n",
    "# ********************************************************************\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "SEED = 5150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los csv's en sendos dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train/train.csv')\n",
    "test = pd.read_csv('test/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que no existen elementos repetidos en ambos dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set(train.id.values).intersection(test.id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set(train.id.values).intersection(test.id.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionamos nuestra variable regresora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train['comment_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionamos nuestras variables objetivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories= [c for c in train.columns if not c in ['id', 'comment_text']]\n",
    "y = train[categories]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separaremos nuestro dataset X en dos conjuntos (entrenamiento y test), con el fin de comprobar la bondad de nuestro modelo clasificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Será nuestro primer modelo clasificador. Antes de pasarle los datos al clasificador, aplicaremos algunas técnicas de vectorización de textos (CountVectorizer y TF-IDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_df=0.95, min_df=2,max_features=300,stop_words=None)\n",
    "tfidf = TfidfTransformer()\n",
    "clf = XGBClassifier(base_estimator='gbtree', objetive='multi:softprob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiremos una tubería para realizar las tres operaciones: vectorización del dataset, matriz de frecuencias y el modelo clasificador que hemos elegido para resolver el problema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('vect', vect), ('tfidf', tfidf), ('clf', clf)],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos definido una variable llamada params que nos ayudará a ajustar algunos de los parámetros que intervienen en el ajuste de la vectorización, la matriz de frecuencia y el modelo. En nuestro caso, ajustaremos el parámetro learning_rate del clasificador jugando con tres valores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'clf__learning_rate': [0.1, 0.05, 0.01],\n",
    "    'clf__max_depth' : [6],\n",
    "    'clf__silent' : [1],\n",
    "    'clf__nthread' : [4]    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la optimización de los parámetros nos serviremos de GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_training = GridSearchCV(pipeline, params, verbose=2, n_jobs=8, refit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como XGBoost no está preparado para trabajar con variables multietiquetas, tendremos que iterar sobre las categorías y ajustar el modelo para cada una de ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score \n",
    "for label in categories:\n",
    "    model_training.fit(X_train, y_train[label])\n",
    "    model_training.predict_proba(X_test)[:,1]\n",
    "    best_parameters, score, _ = max(model_training.grid_scores_, key=lambda x: x[1])\n",
    "    print('Raw AUC score:', score)\n",
    "    for param_name in sorted(best_parameters.keys()):\n",
    "        print(\"%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabiendo los mejores parámetros, podemos probar a mejorarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_params = {\n",
    "    'clf__learning_rate': [0.07, 0.06, 0.05],\n",
    "    'clf__max_depth' : [6],\n",
    "    'clf__silent' : [1],\n",
    "    'clf__nthread' : [4],\n",
    "    'clf__subsample': [0.8],\n",
    "    'clf__colsample_bytree': [0.8],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos de nuevo el modelo, esta vez con todos los datos disponibles en el dataset de entrenamiento. La validación cruzada será necesaria para comprobar si nuestro modelo es lo suficientemente generalista. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = GridSearchCV(pipeline, new_params, n_jobs=8,\n",
    "                      cv=StratifiedKFold(n_splits=5, shuffle=True, random_state= SEED), \n",
    "                      scoring='roc_auc',\n",
    "                      verbose=2, refit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construiremos el dataset con las probabilidades de las predicciones para construir el fichero csv que enviaremos a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame()\n",
    "for label in categories:\n",
    "    model.fit(X, y[label])\n",
    "    pred = model.predict_proba(test[\"comment_text\"])[:,1]\n",
    "    predictions[label] = pd.Series(pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm_XGB = pd.DataFrame(data=predictions, columns=categories)\n",
    "subm_XGB = pd.concat((test, subm_XGB), axis=1)[['id'] + categories]\n",
    "subm_XGB.to_csv(\"subm_XGB.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para Kaggle, el score de nuestro modelo XGBoost  es de 0.8617"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest permite modelar variables multietiqueta. Vamos a ajustar, con la ayuda de OneVsRestClassifier, un clasificador por clase. Para cada clasificador, la clase será ajustada frente a las otras clases.\n",
    "Como en el modelo anterior, definiremos una tubería para aplicar técnicas de vectorización y definir el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(max_features=500, max_df=0.95, min_df=2,\n",
    "                                binary=False,\n",
    "                                stop_words=None)),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', OneVsRestClassifier(RandomForestClassifier(n_jobs=-1, n_estimators=20, random_state=SEED))),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una batería de parámetros para ver con cuáles de ellos conseguimos un mejor ajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'clf__estimator__max_features' : ['auto'], \n",
    "    'clf__estimator__min_samples_leaf': [1,2,3,4,5],\n",
    "    'clf__estimator__criterion': ('gini','entropy')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como en el modelo anterior, nos serviremos de una rejilla para pasarle los parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "model = GridSearchCV(text_clf, params, n_jobs=8, verbose=2, refit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustamos primero el modelo con los datos spliteados del dataset train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos una precisión de 0.9063218063388975"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomamos los mejores parámetros obtenidos en el ajuste anterior y modificamos algunos de ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learned_parameters = model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learned_parameters['clf__estimator__n_estimators'] = [100]\n",
    "learned_parameters['clf__estimator__min_samples_leaf'] = [10]\n",
    "learned_parameters['clf__estimator__criterion'] = ['entropy']\n",
    "learned_parameters['clf__estimator__max_features'] = ['auto']\n",
    "learned_parameters['clf__estimator__max_depth'] = [5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos de nuevo el modelo, esta vez con todos los datos disponibles en el dataset de entrenamiento. La validación cruzada será necesaria para comprobar si nuestro modelo es lo suficientemente generalista. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = GridSearchCV(text_clf, learned_parameters, n_jobs=8,\n",
    "                    cv = 5,\n",
    "                    scoring='roc_auc',\n",
    "                    verbose=2, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos el nuevo score con todos los datos disponibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "scores = cross_val_score(model, X, y, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro score es de 0.9149130169770235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict_proba(test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm_RF = pd.DataFrame(data=pred, columns=categories)\n",
    "subm_RF = pd.concat((test, subm_RF), axis=1)[['id'] + categories]\n",
    "subm_RF.to_csv(\"subm_RF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para Kaggle,  el score de nuestro modelo Random Forest es de 0.8939"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM con Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM es un tipo de red recurrente muy utilizada en la clasificación de textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.layers import SpatialDropout1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_X = list(X.values)\n",
    "list_test = list(test['comment_text'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos un preprocesado de los datos convirtiendo cada palabra en un token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_words = 20000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(list_X + list_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea es tratar cada comentario como una secuencia de palabras. Las redes recurrentes tienen la ventaja de que cada salida depende no sólo de la entrada, si no de la salida anterior, por lo que la red conserva en memoria cada palabra que ha entrado en la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_sequences = tokenizer.texts_to_sequences(X.values)\n",
    "test_sequences = tokenizer.texts_to_sequences(test['comment_text'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La longitud máxima de los comentarios es maxlen = max(X.apply(len)), que en nuestro caso serían 5000; pero mi equipo era incapaz de crear secuencias tan largas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_pad = pad_sequences(X_sequences, maxlen=3000)\n",
    "test_pad = pad_sequences(test_sequences, maxlen=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La red está compuesta por varias capas, cada una de ellas con una función determinada. La primera capa, llamada Embedding, se encargará de codificar la secuencias en vectores, de tal forma que las palabras cuyo significado sean parecidos tendrán vectores parecidos. La segunda capa es SpatialDropout, cuya función es la de evitar el sobreajuste del modelo; la tercera es la capa LSTM propiamente dicha; y la última, es la capa de salida (6 salidas, una por categoría)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_dim = 32\n",
    "lstm_out = 64\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embed_dim, input_length=3000))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(lstm_out, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, dropout_U=0.2, dropout_W=0.2))\n",
    "model.add(Dense(6,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "model.fit(X_pad, y, epochs = 2, batch_size=batch_size, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on 143613 samples, validate on 15958 samples\n",
    "Epoch 1/2\n",
    "143613/143613 [==============================] - 38021s 265ms/step - loss: 0.2949 - acc: 0.9868 - val_loss: 0.2956 - val_acc: 0.9849\n",
    "Epoch 2/2\n",
    "143613/143613 [==============================] - 8722s 61ms/step - loss: 0.2850 - acc: 0.9800 - val_loss: 0.2881 - val_acc: 0.9821"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos da un accuracy de 0.9868"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos las probabilidades para cada categoría y las guardamos en un archivo csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(test_pad, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm_LSTM = pd.DataFrame(data=pred, columns=categories)\n",
    "subm_LSTM = pd.concat((test, subm_LSTM), axis=1)[['id'] + categories]\n",
    "subm_LSTM.to_csv(\"subm_LSTM.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para Kaggle, el score de nuestro modelo de red recurrente es de 0.7375"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pese a la potencia de las redes recurrentes, una red mal diseñada se comporta mucho peor que cualquier otro modelo clásico."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
